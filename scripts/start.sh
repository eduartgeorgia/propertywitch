#!/bin/bash

# AIPA - Start All Services
# Usage: ./scripts/start.sh

set -e  # Exit on error

PROJECT_ROOT="$(cd "$(dirname "$0")/.." && pwd)"
cd "$PROJECT_ROOT"

echo "üöÄ Starting AIPA Services..."

# Ensure logs directory exists
mkdir -p "$PROJECT_ROOT/logs"

# Kill any existing processes on our ports (safe for macOS)
echo "üì¶ Cleaning up existing processes..."
kill_port() {
    local port=$1
    local pids=$(lsof -ti:$port 2>/dev/null)
    if [ -n "$pids" ]; then
        echo "$pids" | xargs kill -9 2>/dev/null || true
    fi
}
kill_port 4000
kill_port 5173

# Check if Ollama is running
echo "ü§ñ Checking Ollama..."
if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "‚ö†Ô∏è  Ollama not running. Starting Ollama..."
    ollama serve > /dev/null 2>&1 &
    sleep 3
fi

# Verify Ollama has models
MODELS=$(curl -s http://localhost:11434/api/tags 2>/dev/null | grep -o '"name"' | wc -l | tr -d ' ')
if [ "$MODELS" -eq 0 ] 2>/dev/null; then
    echo "‚ö†Ô∏è  No Ollama models found. Please run: ollama pull llama3.2"
fi

# Check and install server dependencies if needed
echo "üì¶ Checking server dependencies..."
cd "$PROJECT_ROOT/server"
if [ ! -d "node_modules" ]; then
    echo "   Installing server dependencies..."
    npm install
fi

# Start backend server
echo "üîß Starting Backend Server (port 4000)..."
npm run dev > "$PROJECT_ROOT/logs/server.log" 2>&1 &

# Wait for backend to be FULLY ready (API responding properly)
echo "   Waiting for backend to start..."
for i in {1..30}; do
    # Check if server is responding with valid JSON
    if curl -s http://localhost:4000/ 2>/dev/null | grep -q "ok"; then
        echo "   ‚úì Backend server is ready"
        break
    fi
    if [ $i -eq 30 ]; then
        echo "   ‚ö† Backend still starting - check logs/server.log"
    fi
    sleep 1
done

# Check and install web dependencies if needed
echo "üì¶ Checking web dependencies..."
cd "$PROJECT_ROOT/web"
if [ ! -d "node_modules" ]; then
    echo "   Installing web dependencies..."
    npm install
fi

# Start frontend
echo "üåê Starting Frontend (port 5173)..."
npm run dev > "$PROJECT_ROOT/logs/web.log" 2>&1 &

# Wait for frontend to be ready
echo "   Waiting for frontend to start..."
for i in {1..30}; do
    if curl -s http://localhost:5173 > /dev/null 2>&1; then
        echo "   ‚úì Frontend is ready"
        break
    fi
    if [ $i -eq 30 ]; then
        echo "   ‚ö† Frontend still starting - check logs/web.log"
    fi
    sleep 1
done

# Save PIDs by port (more reliable than $!)
lsof -ti:4000 2>/dev/null > "$PROJECT_ROOT/.server.pid" || true
lsof -ti:5173 2>/dev/null > "$PROJECT_ROOT/.web.pid" || true

echo ""
echo "‚úÖ Services Started!"
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo "ü§ñ Ollama AI:  http://localhost:11434"
echo "üîß Backend:    http://localhost:4000"
echo "üåê Frontend:   http://localhost:5173"
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo ""
echo "üìã Logs: $PROJECT_ROOT/logs/"
echo "üõë Stop: ./scripts/stop.sh"
echo ""

# Health check
if curl -s http://localhost:4000/api/ai/health > /dev/null 2>&1; then
    echo "‚úÖ Backend health check passed"
else
    echo "‚ö†Ô∏è  Backend may still be starting - check logs/server.log"
fi

if curl -s http://localhost:5173 > /dev/null 2>&1; then
    echo "‚úÖ Frontend health check passed"
else
    echo "‚ö†Ô∏è  Frontend may still be starting - check logs/web.log"
fi
